{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standard Machine Learning models",
   "id": "6c25c992f5b80ad9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:16:34.142590Z",
     "start_time": "2025-05-25T18:16:31.062298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\")  # Ensure the parent directory is in the path\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Local Application/Module Imports ---\n",
    "import data_loader.data_loader\n",
    "import data_preprocessing.data_preprocessing\n",
    "import models.standard_ml_models\n",
    "import visualizations.visualizations\n",
    "import utils.utils\n",
    "\n",
    "importlib.reload(data_loader.data_loader)\n",
    "from data_loader.data_loader import *\n",
    "\n",
    "importlib.reload(data_preprocessing.data_preprocessing)\n",
    "from data_preprocessing.data_preprocessing import *\n",
    "\n",
    "importlib.reload(models.standard_ml_models)\n",
    "from models.standard_ml_models import *\n",
    "\n",
    "importlib.reload(visualizations.visualizations)\n",
    "from visualizations.visualizations import *\n",
    "\n",
    "importlib.reload(utils.utils)\n",
    "from utils.utils import *\n",
    "\n",
    "# --- Notebook Configuration ---\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# --- Global Settings ---\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "id": "c4a4cc26a44cf154",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading data and splitting into train, validation, and test sets",
   "id": "e0f434313ee302bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:16:36.111915Z",
     "start_time": "2025-05-25T18:16:35.978825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, val_df, test_df = load_and_split_data()\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))"
   ],
   "id": "78615802f0f8833a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 81677\n",
      "Validation size: 10210\n",
      "Test size: 10210\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bag-of-words - Baseline models",
   "id": "e74138734bd8b710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:13.303147Z",
     "start_time": "2025-05-23T15:37:11.847943Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df, val_df, test_df)",
   "id": "1b9c1e0518dc588d",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:14.929704Z",
     "start_time": "2025-05-23T15:37:13.379535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "521daeba4efd9d08",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:15.048657Z",
     "start_time": "2025-05-23T15:37:15.029546Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "c896cbb2b2bf674e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:15.178706Z",
     "start_time": "2025-05-23T15:37:15.173810Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "d52c302fcb8c28ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:33:39.653850Z",
     "start_time": "2025-05-23T15:32:56.215520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Random Forest model\n",
    "y_train_pred_rf, y_val_pred_rf, y_test_pred_rf, model_rf = train_and_predict_random_forest(X_train, y_train, X_val, X_test)"
   ],
   "id": "ee3a437c28906137",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:33:39.761715Z",
     "start_time": "2025-05-23T15:33:39.751663Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_rf)",
   "id": "6a6927501a871514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      0.28      0.38      2191\n",
      "     neutral       0.63      0.89      0.74      4915\n",
      "    positive       0.70      0.50      0.58      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.65      0.56      0.57     10210\n",
      "weighted avg       0.65      0.64      0.61     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:33:39.857815Z",
     "start_time": "2025-05-23T15:33:39.855760Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_rf))",
   "id": "8bcc13b9ee2b6677",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7954946131243879\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.326948Z",
     "start_time": "2025-05-23T15:06:59.035423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a XGBoost model\n",
    "y_train_pred_xgb, y_val_pred_xgb, y_test_pred_xgb, model_xgb = train_and_predict_xgboost(X_train, y_train, X_val, X_test)"
   ],
   "id": "12e6f4dc316a9141",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.407702Z",
     "start_time": "2025-05-23T15:07:00.397101Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_xgb)",
   "id": "b0edd2f56abf5ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.41      2191\n",
      "     neutral       0.62      0.92      0.74      4915\n",
      "    positive       0.74      0.47      0.57      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.68      0.56      0.58     10210\n",
      "weighted avg       0.67      0.65      0.62     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.484327Z",
     "start_time": "2025-05-23T15:07:00.481720Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_xgb))",
   "id": "b0590323f529b80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027913809990206\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:53.958044Z",
     "start_time": "2025-05-23T15:07:00.554043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a MLP model\n",
    "y_train_pred_mlp, y_val_pred_mlp, y_test_pred_mlp, model_mlp = train_and_predict_mlp(X_train, y_train, X_val, X_test)"
   ],
   "id": "485f30a1f3cd799b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:54.094159Z",
     "start_time": "2025-05-23T15:08:54.078659Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_mlp)",
   "id": "82f2cd1b220cb7ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.40      0.46      2191\n",
      "     neutral       0.69      0.77      0.73      4915\n",
      "    positive       0.61      0.60      0.60      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.61      0.59      0.60     10210\n",
      "weighted avg       0.63      0.64      0.63     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:54.219610Z",
     "start_time": "2025-05-23T15:08:54.188992Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_mlp))",
   "id": "42f75bd83c0b82cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7782076395690499\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data preprocessing",
   "id": "1ba3dfe49b9e5699"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:33.693947Z",
     "start_time": "2025-05-23T15:37:29.922392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lowercase = preprocess_ml_pipeline(train_df, [\"lowercase\"])\n",
    "val_df_lowercase = preprocess_ml_pipeline(val_df, [\"lowercase\"])\n",
    "test_df_lowercase = preprocess_ml_pipeline(test_df, [\"lowercase\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lowercase, val_df_lowercase, test_df_lowercase)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "bcc4355cd13abd41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "bag of words transforms to lowercase by default, so this step is redundant",
   "id": "c0ee0784ddfc9abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:38.821721Z",
     "start_time": "2025-05-23T15:37:33.842773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_expand_contractions = preprocess_ml_pipeline(train_df, [\"expand_contractions\"])\n",
    "val_df_expand_contractions = preprocess_ml_pipeline(val_df, [\"expand_contractions\"])\n",
    "test_df_expand_contractions = preprocess_ml_pipeline(test_df, [\"expand_contractions\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_expand_contractions, val_df_expand_contractions, test_df_expand_contractions)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "70097e3db0d62ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.40      0.49      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8057296767874633\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:41.885986Z",
     "start_time": "2025-05-23T15:37:38.952522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_emails = preprocess_ml_pipeline(train_df, [\"remove_emails\"])\n",
    "val_df_remove_emails = preprocess_ml_pipeline(val_df, [\"remove_emails\"])\n",
    "test_df_remove_emails = preprocess_ml_pipeline(test_df, [\"remove_emails\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_emails, val_df_remove_emails, test_df_remove_emails)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "784a74f22652d890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.804407443682664\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:45.057685Z",
     "start_time": "2025-05-23T15:37:42.001868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_urls = preprocess_ml_pipeline(train_df, [\"remove_urls\"])\n",
    "val_df_remove_urls = preprocess_ml_pipeline(val_df, [\"remove_urls\"])\n",
    "test_df_remove_urls = preprocess_ml_pipeline(test_df, [\"remove_urls\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_urls, val_df_remove_urls, test_df_remove_urls)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "e7cb9028a5c22ecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8041625857002939\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:48.149714Z",
     "start_time": "2025-05-23T15:37:45.176796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_digits = preprocess_ml_pipeline(train_df, [\"remove_digits\"])\n",
    "val_df_remove_digits = preprocess_ml_pipeline(val_df, [\"remove_digits\"])\n",
    "test_df_remove_digits = preprocess_ml_pipeline(test_df, [\"remove_digits\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_digits, val_df_remove_digits, test_df_remove_digits)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "45bbe5c788e740d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.47      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.63      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8036728697355534\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:51.188999Z",
     "start_time": "2025-05-23T15:37:48.274641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_special_chars = preprocess_ml_pipeline(train_df, [\"remove_special_chars\"])\n",
    "val_df_remove_special_chars = preprocess_ml_pipeline(val_df, [\"remove_special_chars\"])\n",
    "test_df_remove_special_chars = preprocess_ml_pipeline(test_df, [\"remove_special_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_special_chars, val_df_remove_special_chars, test_df_remove_special_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "d2e564d8be3c634d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:54.094534Z",
     "start_time": "2025-05-23T15:37:51.301370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_collapse_spaces = preprocess_ml_pipeline(train_df, [\"collapse_spaces\"])\n",
    "val_df_collapse_spaces = preprocess_ml_pipeline(val_df, [\"collapse_spaces\"])\n",
    "test_df_collapse_spaces = preprocess_ml_pipeline(test_df, [\"collapse_spaces\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_collapse_spaces, val_df_collapse_spaces, test_df_collapse_spaces)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "dd34e3976a8cc92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:57.206433Z",
     "start_time": "2025-05-23T15:37:54.203224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_accented_chars = preprocess_ml_pipeline(train_df, [\"remove_accented_chars\"])\n",
    "val_df_remove_accented_chars = preprocess_ml_pipeline(val_df, [\"remove_accented_chars\"])\n",
    "test_df_remove_accented_chars = preprocess_ml_pipeline(test_df, [\"remove_accented_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_accented_chars, val_df_remove_accented_chars, test_df_remove_accented_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "772008222d333f69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8037708129285015\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:38:16.737573Z",
     "start_time": "2025-05-23T15:38:11.505869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_stopwords = preprocess_ml_pipeline(train_df, [\"remove_stopwords\"])\n",
    "val_df_remove_stopwords = preprocess_ml_pipeline(val_df, [\"remove_stopwords\"])\n",
    "test_df_remove_stopwords = preprocess_ml_pipeline(test_df, [\"remove_stopwords\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_stopwords, val_df_remove_stopwords, test_df_remove_stopwords)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "9739522499f070e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.34      0.43      2191\n",
      "     neutral       0.66      0.87      0.75      4915\n",
      "    positive       0.69      0.55      0.62      3104\n",
      "\n",
      "    accuracy                           0.66     10210\n",
      "   macro avg       0.65      0.59      0.60     10210\n",
      "weighted avg       0.66      0.66      0.64     10210\n",
      "\n",
      "0.800048971596474\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:39:43.838148Z",
     "start_time": "2025-05-23T15:39:34.606053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lemmatize = preprocess_ml_pipeline(train_df, [\"lemmatize\"])\n",
    "val_df_lemmatize = preprocess_ml_pipeline(val_df, [\"lemmatize\"])\n",
    "test_df_lemmatize = preprocess_ml_pipeline(test_df, [\"lemmatize\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lemmatize, val_df_lemmatize, test_df_lemmatize)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "60109b80b89118bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.39      0.47      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.60      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8032321253672869\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:39:08.594399Z",
     "start_time": "2025-05-23T15:39:02.746292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_filter_valid_words = preprocess_ml_pipeline(train_df, [\"filter_valid_words\"])\n",
    "val_df_filter_valid_words = preprocess_ml_pipeline(val_df, [\"filter_valid_words\"])\n",
    "test_df_filter_valid_words = preprocess_ml_pipeline(test_df, [\"filter_valid_words\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_filter_valid_words, val_df_filter_valid_words, test_df_filter_valid_words)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "97368b7a4168dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.36      0.45      2191\n",
      "     neutral       0.65      0.87      0.74      4915\n",
      "    positive       0.68      0.51      0.59      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.64      0.58      0.59     10210\n",
      "weighted avg       0.65      0.65      0.63     10210\n",
      "\n",
      "0.794466209598433\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "| Preprocessing Step     | L_score               |\n",
    "|------------------------|-----------------------|\n",
    "| baseline               | 0.8040646425073458    |\n",
    "| expand_contractions    | 0.8057296767874633    |\n",
    "| remove_emails          | 0.804407443682664     |\n",
    "| remove_urls            | 0.8041625857002939    |\n",
    "\n",
    "We can see that the preprocessing steps have a small impact on the model performance. The best performing model is the one with the \"expand_contractions\" step, which has a slight improvement over the baseline. The other steps have negligible effects on the performance.\n",
    "\n",
    "To attain better results, we will explore with fine-tuning Roberta in the next notebook. We will explore ways to sanitize and augment the dataset using LLMs and various other techniques."
   ],
   "id": "fb3da437b2280536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2231cf3e6fc07b3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
