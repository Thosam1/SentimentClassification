{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standard Machine Learning models",
   "id": "6c25c992f5b80ad9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:47:51.639904Z",
     "start_time": "2025-05-25T21:47:51.435315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"..\")  # Ensure the parent directory is in the path\n",
    "\n",
    "# --- Local Application/Module Imports ---\n",
    "import data_loader.data_loader\n",
    "import data_preprocessing.data_preprocessing\n",
    "import models.standard_ml_models\n",
    "import visualizations.visualizations\n",
    "import utils.utils\n",
    "\n",
    "importlib.reload(data_loader.data_loader)\n",
    "from data_loader.data_loader import *\n",
    "\n",
    "importlib.reload(data_preprocessing.data_preprocessing)\n",
    "from data_preprocessing.data_preprocessing import *\n",
    "\n",
    "importlib.reload(models.standard_ml_models)\n",
    "from models.standard_ml_models import *\n",
    "\n",
    "importlib.reload(visualizations.visualizations)\n",
    "from visualizations.visualizations import *\n",
    "\n",
    "importlib.reload(utils.utils)\n",
    "from utils.utils import *\n",
    "\n",
    "# --- Notebook Configuration ---\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# --- Global Settings ---\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "id": "c4a4cc26a44cf154",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading data and splitting into train, validation, and test sets",
   "id": "e0f434313ee302bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:25:59.752702Z",
     "start_time": "2025-05-25T18:25:59.624687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, val_df, test_df = load_and_split_data()\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))"
   ],
   "id": "78615802f0f8833a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 81677\n",
      "Validation size: 10210\n",
      "Test size: 10210\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bag-of-words - Baseline models",
   "id": "e74138734bd8b710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:02.580429Z",
     "start_time": "2025-05-25T18:26:01.143218Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df, val_df, test_df)",
   "id": "1b9c1e0518dc588d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "9633d96f56167a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:04.483644Z",
     "start_time": "2025-05-25T18:26:02.646685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "521daeba4efd9d08",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:04.608017Z",
     "start_time": "2025-05-25T18:26:04.576630Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "c896cbb2b2bf674e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:04.733498Z",
     "start_time": "2025-05-25T18:26:04.728657Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "d52c302fcb8c28ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "5d8537ad6f566830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:14.017126Z",
     "start_time": "2025-05-25T18:26:04.804157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Random Forest model\n",
    "y_train_pred_rf, y_val_pred_rf, y_test_pred_rf, model_rf = train_and_predict_random_forest(X_train, y_train, X_val, X_test)"
   ],
   "id": "ee3a437c28906137",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:14.102725Z",
     "start_time": "2025-05-25T18:26:14.090711Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_rf)",
   "id": "6a6927501a871514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.28      0.39      2191\n",
      "     neutral       0.63      0.89      0.73      4915\n",
      "    positive       0.68      0.49      0.57      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.64      0.55      0.57     10210\n",
      "weighted avg       0.64      0.64      0.61     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:26:14.176896Z",
     "start_time": "2025-05-25T18:26:14.174688Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_rf))",
   "id": "8bcc13b9ee2b6677",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923604309500489\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "31999ec6dc9eecd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.326948Z",
     "start_time": "2025-05-23T15:06:59.035423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a XGBoost model\n",
    "y_train_pred_xgb, y_val_pred_xgb, y_test_pred_xgb, model_xgb = train_and_predict_xgboost(X_train, y_train, X_val, X_test)"
   ],
   "id": "12e6f4dc316a9141",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.407702Z",
     "start_time": "2025-05-23T15:07:00.397101Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_xgb)",
   "id": "b0edd2f56abf5ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.41      2191\n",
      "     neutral       0.62      0.92      0.74      4915\n",
      "    positive       0.74      0.47      0.57      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.68      0.56      0.58     10210\n",
      "weighted avg       0.67      0.65      0.62     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:07:00.484327Z",
     "start_time": "2025-05-23T15:07:00.481720Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_xgb))",
   "id": "b0590323f529b80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027913809990206\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MLP",
   "id": "a30e1b9374828b8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:53.958044Z",
     "start_time": "2025-05-23T15:07:00.554043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a MLP model\n",
    "y_train_pred_mlp, y_val_pred_mlp, y_test_pred_mlp, model_mlp = train_and_predict_mlp(X_train, y_train, X_val, X_test)"
   ],
   "id": "485f30a1f3cd799b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:54.094159Z",
     "start_time": "2025-05-23T15:08:54.078659Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_mlp)",
   "id": "82f2cd1b220cb7ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.40      0.46      2191\n",
      "     neutral       0.69      0.77      0.73      4915\n",
      "    positive       0.61      0.60      0.60      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.61      0.59      0.60     10210\n",
      "weighted avg       0.63      0.64      0.63     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:08:54.219610Z",
     "start_time": "2025-05-23T15:08:54.188992Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_mlp))",
   "id": "42f75bd83c0b82cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7782076395690499\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing\n",
    "\n",
    "### Lowercase"
   ],
   "id": "1ba3dfe49b9e5699"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:33.693947Z",
     "start_time": "2025-05-23T15:37:29.922392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lowercase = preprocess_ml_pipeline(train_df, [\"lowercase\"])\n",
    "val_df_lowercase = preprocess_ml_pipeline(val_df, [\"lowercase\"])\n",
    "test_df_lowercase = preprocess_ml_pipeline(test_df, [\"lowercase\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lowercase, val_df_lowercase, test_df_lowercase)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "bcc4355cd13abd41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "bag of words transforms to lowercase by default, so this step is redundant",
   "id": "c0ee0784ddfc9abf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Expand contractions",
   "id": "8cbf4ea059b428e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:38.821721Z",
     "start_time": "2025-05-23T15:37:33.842773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_expand_contractions = preprocess_ml_pipeline(train_df, [\"expand_contractions\"])\n",
    "val_df_expand_contractions = preprocess_ml_pipeline(val_df, [\"expand_contractions\"])\n",
    "test_df_expand_contractions = preprocess_ml_pipeline(test_df, [\"expand_contractions\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_expand_contractions, val_df_expand_contractions, test_df_expand_contractions)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "70097e3db0d62ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.40      0.49      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8057296767874633\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove emails",
   "id": "996630a7764abb28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:41.885986Z",
     "start_time": "2025-05-23T15:37:38.952522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_emails = preprocess_ml_pipeline(train_df, [\"remove_emails\"])\n",
    "val_df_remove_emails = preprocess_ml_pipeline(val_df, [\"remove_emails\"])\n",
    "test_df_remove_emails = preprocess_ml_pipeline(test_df, [\"remove_emails\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_emails, val_df_remove_emails, test_df_remove_emails)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "784a74f22652d890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.804407443682664\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove urls",
   "id": "a8bed95d73570fad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:45.057685Z",
     "start_time": "2025-05-23T15:37:42.001868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_urls = preprocess_ml_pipeline(train_df, [\"remove_urls\"])\n",
    "val_df_remove_urls = preprocess_ml_pipeline(val_df, [\"remove_urls\"])\n",
    "test_df_remove_urls = preprocess_ml_pipeline(test_df, [\"remove_urls\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_urls, val_df_remove_urls, test_df_remove_urls)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "e7cb9028a5c22ecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8041625857002939\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove digits",
   "id": "c94ea8da71923a54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:48.149714Z",
     "start_time": "2025-05-23T15:37:45.176796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_digits = preprocess_ml_pipeline(train_df, [\"remove_digits\"])\n",
    "val_df_remove_digits = preprocess_ml_pipeline(val_df, [\"remove_digits\"])\n",
    "test_df_remove_digits = preprocess_ml_pipeline(test_df, [\"remove_digits\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_digits, val_df_remove_digits, test_df_remove_digits)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "45bbe5c788e740d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.47      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.63      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8036728697355534\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove special characters",
   "id": "5df977e8ca2b3e81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:51.188999Z",
     "start_time": "2025-05-23T15:37:48.274641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_special_chars = preprocess_ml_pipeline(train_df, [\"remove_special_chars\"])\n",
    "val_df_remove_special_chars = preprocess_ml_pipeline(val_df, [\"remove_special_chars\"])\n",
    "test_df_remove_special_chars = preprocess_ml_pipeline(test_df, [\"remove_special_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_special_chars, val_df_remove_special_chars, test_df_remove_special_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "d2e564d8be3c634d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collapse spaces",
   "id": "e25afaded505cd86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:54.094534Z",
     "start_time": "2025-05-23T15:37:51.301370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_collapse_spaces = preprocess_ml_pipeline(train_df, [\"collapse_spaces\"])\n",
    "val_df_collapse_spaces = preprocess_ml_pipeline(val_df, [\"collapse_spaces\"])\n",
    "test_df_collapse_spaces = preprocess_ml_pipeline(test_df, [\"collapse_spaces\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_collapse_spaces, val_df_collapse_spaces, test_df_collapse_spaces)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "dd34e3976a8cc92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This step is also redundant as it is already done.",
   "id": "399a0d6c7f7b450c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove accented characters",
   "id": "3451f786623274d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:37:57.206433Z",
     "start_time": "2025-05-23T15:37:54.203224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_accented_chars = preprocess_ml_pipeline(train_df, [\"remove_accented_chars\"])\n",
    "val_df_remove_accented_chars = preprocess_ml_pipeline(val_df, [\"remove_accented_chars\"])\n",
    "test_df_remove_accented_chars = preprocess_ml_pipeline(test_df, [\"remove_accented_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_accented_chars, val_df_remove_accented_chars, test_df_remove_accented_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "772008222d333f69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8037708129285015\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove stopwords",
   "id": "db41ddf1194c847c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:38:16.737573Z",
     "start_time": "2025-05-23T15:38:11.505869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_stopwords = preprocess_ml_pipeline(train_df, [\"remove_stopwords\"])\n",
    "val_df_remove_stopwords = preprocess_ml_pipeline(val_df, [\"remove_stopwords\"])\n",
    "test_df_remove_stopwords = preprocess_ml_pipeline(test_df, [\"remove_stopwords\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_stopwords, val_df_remove_stopwords, test_df_remove_stopwords)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "9739522499f070e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.34      0.43      2191\n",
      "     neutral       0.66      0.87      0.75      4915\n",
      "    positive       0.69      0.55      0.62      3104\n",
      "\n",
      "    accuracy                           0.66     10210\n",
      "   macro avg       0.65      0.59      0.60     10210\n",
      "weighted avg       0.66      0.66      0.64     10210\n",
      "\n",
      "0.800048971596474\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lemmatize",
   "id": "d8e0061f7338c8e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:39:43.838148Z",
     "start_time": "2025-05-23T15:39:34.606053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lemmatize = preprocess_ml_pipeline(train_df, [\"lemmatize\"])\n",
    "val_df_lemmatize = preprocess_ml_pipeline(val_df, [\"lemmatize\"])\n",
    "test_df_lemmatize = preprocess_ml_pipeline(test_df, [\"lemmatize\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lemmatize, val_df_lemmatize, test_df_lemmatize)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "60109b80b89118bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.39      0.47      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.60      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8032321253672869\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Filter valid words",
   "id": "16b443682df8f782"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:39:08.594399Z",
     "start_time": "2025-05-23T15:39:02.746292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_filter_valid_words = preprocess_ml_pipeline(train_df, [\"filter_valid_words\"])\n",
    "val_df_filter_valid_words = preprocess_ml_pipeline(val_df, [\"filter_valid_words\"])\n",
    "test_df_filter_valid_words = preprocess_ml_pipeline(test_df, [\"filter_valid_words\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_filter_valid_words, val_df_filter_valid_words, test_df_filter_valid_words)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "97368b7a4168dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.36      0.45      2191\n",
      "     neutral       0.65      0.87      0.74      4915\n",
      "    positive       0.68      0.51      0.59      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.64      0.58      0.59     10210\n",
      "weighted avg       0.65      0.65      0.63     10210\n",
      "\n",
      "0.794466209598433\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Removing non-English inputs in the training set",
   "id": "ec3c55565fbb0694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:01:21.655580Z",
     "start_time": "2025-05-25T20:01:21.653507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "DetectorFactory.seed = RANDOM_SEED  # for reproducibility\n",
    "\n",
    "# Detect language for each text in train_df, handle empty strings\n",
    "def safe_detect(text):\n",
    "\ttext = str(text).strip()\n",
    "\tif not text:\n",
    "\t\treturn 'unknown'\n",
    "\ttry:\n",
    "\t\treturn detect(text)\n",
    "\texcept Exception:\n",
    "\t\treturn 'unknown'\n",
    "\n",
    "train_df['language'] = train_df['text'].apply(safe_detect)\n",
    "\n",
    "# Get indices of samples for each language as a dictionary\n",
    "language_indices = {lang: train_df.index[train_df['language'] == lang].tolist() for lang in train_df['language'].unique()}"
   ],
   "id": "d668820b8c947618",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:01:30.025280Z",
     "start_time": "2025-05-25T20:01:30.023376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_counts = {lang: len(indices) for lang, indices in language_indices.items()}\n",
    "print(language_counts)"
   ],
   "id": "276ede7845b501a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 77388, 'it': 223, 'fr': 533, 'so': 254, 'af': 504, 'unknown': 44, 'nl': 270, 'ca': 137, 'tl': 173, 'no': 279, 'sw': 62, 'et': 122, 'da': 304, 'sv': 78, 'id': 109, 'de': 293, 'sq': 46, 'fi': 38, 'pl': 64, 'pt': 82, 'vi': 69, 'zh-cn': 4, 'cy': 192, 'ro': 112, 'es': 124, 'hu': 33, 'sl': 22, 'tr': 34, 'lt': 13, 'hr': 15, 'cs': 24, 'lv': 10, 'sk': 17, 'ja': 3, 'uk': 2}\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:27:25.274911Z",
     "start_time": "2025-05-25T20:27:25.270258Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.loc[language_indices['it'][:5]].copy()",
   "id": "4794689d1512fa95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            text  labels language\n",
       "id                                                               \n",
       "47402                    I give a 5 on ambiance.       2       it\n",
       "58212                                     Hello!       1       it\n",
       "52818  Second: I've never had tomatoes ll pizza.       1       it\n",
       "57961                           I'm a carnivore.       1       it\n",
       "73345                          I prefer Spinatos       1       it"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47402</th>\n",
       "      <td>I give a 5 on ambiance.</td>\n",
       "      <td>2</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58212</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52818</th>\n",
       "      <td>Second: I've never had tomatoes ll pizza.</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57961</th>\n",
       "      <td>I'm a carnivore.</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73345</th>\n",
       "      <td>I prefer Spinatos</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using this library leads to many classification error.\n",
    "\n",
    "\n",
    "However, let's just keep the english samples and remove the rest for training, just to have an idea of if we are going into the right direction."
   ],
   "id": "5da9e4a4de8af0bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:22:07.866615Z",
     "start_time": "2025-05-25T20:22:07.852962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "english_train_df = train_df.loc[language_indices['en']].copy()"
   ],
   "id": "bd12a2e8c4377156",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:24:50.978212Z",
     "start_time": "2025-05-25T20:24:49.675349Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(english_train_df, val_df, test_df)",
   "id": "f1429ad8ea365418",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:24:54.008129Z",
     "start_time": "2025-05-25T20:24:51.916334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "38af95a1a897ea94",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:24:54.127297Z",
     "start_time": "2025-05-25T20:24:54.110200Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "da82aae23a2e1ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.69      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:24:54.295873Z",
     "start_time": "2025-05-25T20:24:54.293586Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "8320ac1c5cdaae44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034280117531831\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b095bf9f445b656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:48:03.576005Z",
     "start_time": "2025-05-25T21:48:03.569090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "\n",
    "def load_language_detection_pipeline(model_name: str):\n",
    "    \"\"\"\n",
    "    Loads a Hugging Face language classification pipeline.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model on Hugging Face Hub.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: A Hugging Face text classification pipeline.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    device = get_device()\n",
    "    return pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "def add_detected_language_column(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text',\n",
    "    new_column: str = 'transformer_language',\n",
    "    model_name: str = 'qanastek/51-languages-classifier'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column with language predictions to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a column of text data.\n",
    "        text_column (str): Name of the column containing the text.\n",
    "        new_column (str): Name of the column to store predicted language labels.\n",
    "        model_name (str): Hugging Face model name for language detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column containing language labels.\n",
    "    \"\"\"\n",
    "    lang_pipeline = load_language_detection_pipeline(model_name)\n",
    "    tqdm.pandas(desc=\"Detecting languages\")\n",
    "\n",
    "    def classify(text: str) -> str:\n",
    "        text = str(text).strip()\n",
    "        if not text:\n",
    "            return 'unknown'\n",
    "        try:\n",
    "            result = lang_pipeline(text, truncation=True, max_length=512)\n",
    "            return result[0]['label']\n",
    "        except Exception:\n",
    "            return 'unknown'\n",
    "\n",
    "    df[new_column] = df[text_column].progress_apply(classify)\n",
    "    return df\n",
    "\n",
    "def add_detected_language_column_batch(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text',\n",
    "    new_column: str = 'transformer_language',\n",
    "    model_name: str = 'qanastek/51-languages-classifier',\n",
    "    batch_size: int = 32\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds a new column with language predictions to the DataFrame using batch processing.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with a column of text data.\n",
    "        text_column (str): Name of the column containing the text.\n",
    "        new_column (str): Name of the column to store predicted language labels.\n",
    "        model_name (str): Hugging Face model name for language detection.\n",
    "        batch_size (int): Number of texts to process per batch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional column containing language labels.\n",
    "    \"\"\"\n",
    "    lang_pipeline = load_language_detection_pipeline(model_name)\n",
    "    texts = df[text_column].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "    labels = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Detecting languages in batches\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        try:\n",
    "            results = lang_pipeline(batch, truncation=True, max_length=512)\n",
    "            batch_labels = [r['label'] if isinstance(r, dict) else 'unknown' for r in results]\n",
    "        except Exception:\n",
    "            batch_labels = ['unknown'] * len(batch)\n",
    "        labels.extend(batch_labels)\n",
    "\n",
    "    df[new_column] = labels\n",
    "    return df\n"
   ],
   "id": "44c03e002065cde2",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:13.082150Z",
     "start_time": "2025-05-25T21:52:13.002057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_df_with_languages = add_detected_language_column_batch(\n",
    "#     train_df, batch_size=256\n",
    "# )\n",
    "\n",
    "train_df_with_languages = pd.read_csv('train_df_with_languages.csv')"
   ],
   "id": "4808ecaa4052d79",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:14.115651Z",
     "start_time": "2025-05-25T21:52:13.931539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get indices of samples for each language as a dictionary\n",
    "language_indices = {lang: train_df_with_languages.index[train_df_with_languages['transformer_language'] == lang].tolist() for lang in train_df_with_languages['transformer_language'].unique()}"
   ],
   "id": "db9fe8a36064800c",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:14.279647Z",
     "start_time": "2025-05-25T21:52:14.277774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_counts = {lang: len(indices) for lang, indices in language_indices.items()}\n",
    "print(language_counts)"
   ],
   "id": "f3a6b7878955e30c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en-US': 79095, 'fr-FR': 373, 'ar-SA': 815, 'nl-NL': 166, 'km-KH': 106, 'es-ES': 69, 'jv-ID': 45, 'ro-RO': 67, 'de-DE': 146, 'sv-SE': 36, 'tl-PH': 72, 'ms-MY': 18, 'pt-PT': 38, 'cy-GB': 51, 'lv-LV': 36, 'zh-CN': 5, 'fi-FI': 46, 'id-ID': 12, 'pl-PL': 38, 'sw-KE': 40, 'tr-TR': 10, 'hu-HU': 6, 'nb-NO': 18, 'zh-TW': 21, 'it-IT': 39, 'af-ZA': 124, 'te-IN': 3, 'mn-MN': 12, 'th-TH': 11, 'az-AZ': 22, 'kn-IN': 26, 'hi-IN': 9, 'bn-BD': 7, 'ur-PK': 3, 'ja-JP': 27, 'is-IS': 2, 'vi-VN': 9, 'sl-SL': 9, 'ka-GE': 11, 'da-DK': 8, 'ml-IN': 2, 'he-IL': 7, 'sq-AL': 6, 'hy-AM': 3, 'ru-RU': 2, 'ta-IN': 5, 'am-ET': 1}\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:53:56.177941Z",
     "start_time": "2025-05-25T21:53:56.174353Z"
    }
   },
   "cell_type": "code",
   "source": "train_df_with_languages.loc[language_indices['fr-FR'][:5]].copy()",
   "id": "2b863c9390ea31f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  labels language  \\\n",
       "20   Une chance que les portions étaient aussi géné...       1       fr   \n",
       "271                                      Bon appétit !       2       fr   \n",
       "301      One ca n't deny its seriousness and quality .       2       en   \n",
       "354                                  2 for 1 coup-ons.       1       en   \n",
       "765  They got your head, ear, neck, hands and your ...       1       en   \n",
       "\n",
       "    transformer_language  \n",
       "20                 fr-FR  \n",
       "271                fr-FR  \n",
       "301                fr-FR  \n",
       "354                fr-FR  \n",
       "765                fr-FR  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>language</th>\n",
       "      <th>transformer_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Une chance que les portions étaient aussi géné...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Bon appétit !</td>\n",
       "      <td>2</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>One ca n't deny its seriousness and quality .</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2 for 1 coup-ons.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>They got your head, ear, neck, hands and your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:18.998253Z",
     "start_time": "2025-05-25T21:52:18.994407Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_df_with_languages)",
   "id": "edff16590d6e1059",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81677"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:20.442939Z",
     "start_time": "2025-05-25T21:52:20.429829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "english_train_df = train_df_with_languages.loc[language_indices['en-US']].copy()\n",
    "\n",
    "english_train_df.head(5)"
   ],
   "id": "f9e7a26f0c266cfa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  labels language  \\\n",
       "0            I'm just glad I wasn't paying the bill.       0       en   \n",
       "1                       We decided to give it a try.       1       en   \n",
       "2                                    Food was tasty.       2       en   \n",
       "3  When ` science fiction ' takes advantage of th...       0       en   \n",
       "4   I went here to have my iPhone 6 screen replaced.       1       en   \n",
       "\n",
       "  transformer_language  \n",
       "0                en-US  \n",
       "1                en-US  \n",
       "2                en-US  \n",
       "3                en-US  \n",
       "4                en-US  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>language</th>\n",
       "      <th>transformer_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm just glad I wasn't paying the bill.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We decided to give it a try.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was tasty.</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When ` science fiction ' takes advantage of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went here to have my iPhone 6 screen replaced.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:21.734757Z",
     "start_time": "2025-05-25T21:52:21.729639Z"
    }
   },
   "cell_type": "code",
   "source": "english_train_df.text",
   "id": "107a4af4a41c9053",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  I'm just glad I wasn't paying the bill.\n",
       "1                             We decided to give it a try.\n",
       "2                                          Food was tasty.\n",
       "3        When ` science fiction ' takes advantage of th...\n",
       "4         I went here to have my iPhone 6 screen replaced.\n",
       "                               ...                        \n",
       "81672    I got the sundae and asked for extra chocolate...\n",
       "81673    We had to go there because they said the one i...\n",
       "81674          Asking how we met like it's their business.\n",
       "81675                                                STOP!\n",
       "81676     At 110 degrees our old air conditioner went out.\n",
       "Name: text, Length: 79095, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:25.960842Z",
     "start_time": "2025-05-25T21:52:24.627224Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(english_train_df, val_df, test_df)",
   "id": "cf392f6560320b36",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:31.952113Z",
     "start_time": "2025-05-25T21:52:30.165240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "84e49bba2319bc3b",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:32.116608Z",
     "start_time": "2025-05-25T21:52:32.102981Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "401e53d5ff7c4b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.39      0.47      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.69      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.60      0.62     10210\n",
      "weighted avg       0.66      0.67      0.65     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T21:52:32.262279Z",
     "start_time": "2025-05-25T21:52:32.260072Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "cb3be5d43f9e9e0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024485798237022\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove emails + urls and expand contractions",
   "id": "2a664851eb6d50b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T19:24:25.410490Z",
     "start_time": "2025-05-25T19:24:20.425428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_final = preprocess_ml_pipeline(train_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "val_df_final = preprocess_ml_pipeline(val_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "test_df_final = preprocess_ml_pipeline(test_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_final, val_df_final, test_df_final)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "7b6a527c4f07d5ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.40      0.49      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.67      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8062683643486778\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "| Model                                      | L_score | Accuracy | Precision (N/Ne/P)   | Recall (N/Ne/P)       | F1-score (N/Ne/P)     | Weighted F1 |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| LogReg                                     | 0.8041  | 0.67     | 0.61 / 0.68 / 0.69  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| LogReg + expand contractions                | 0.8057  | 0.67     | 0.62 / 0.68 / 0.70  | 0.40 / 0.86 / 0.56    | 0.49 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg + remove emails                       | 0.8044  | 0.67     | 0.61 / 0.68 / 0.70  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg + remove urls                         | 0.8042  | 0.67     | 0.61 / 0.68 / 0.69  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg combined (expand contractions, remove urls + emails) | 0.8063  | 0.67     | 0.62 / 0.68 / 0.70  | 0.40 / 0.86 / 0.57    | 0.49 / 0.76 / 0.62    | 0.66        |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| RF                                         | 0.7924  | 0.64     | 0.61 / 0.63 / 0.68  | 0.28 / 0.89 / 0.49    | 0.39 / 0.73 / 0.57    | 0.61        |\n",
    "| XGBoost                                    | 0.8028  | 0.65     | 0.67 / 0.62 / 0.74  | 0.29 / 0.92 / 0.47    | 0.41 / 0.74 / 0.57    | 0.62        |\n",
    "| MLP                                        | 0.7782  | 0.64     | 0.53 / 0.69 / 0.61  | 0.40 / 0.77 / 0.60    | 0.46 / 0.73 / 0.60    | 0.63        |\n",
    "\n",
    "\n",
    "We can see that the preprocessing steps have a small impact on the model performance. The best performing model is the one with the \"expand_contractions\" step, which has a slight improvement over the baseline. The other steps have negligible effects on the performance.\n",
    "\n",
    "To attain better results, we will explore with fine-tuning Roberta in the next notebook. We will explore ways to sanitize and augment the dataset using LLMs and various other techniques."
   ],
   "id": "fb3da437b2280536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2231cf3e6fc07b3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
