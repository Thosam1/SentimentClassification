{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standard Machine Learning models",
   "id": "6c25c992f5b80ad9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:00.751493Z",
     "start_time": "2025-05-29T22:27:52.638348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Ensure the parent directory is in the path\n",
    "\n",
    "# --- Local Application/Module Imports ---\n",
    "import data_loader.data_loader\n",
    "import data_preprocessing.data_preprocessing\n",
    "import models.standard_ml_models\n",
    "import visualizations.visualizations\n",
    "import utils.utils\n",
    "\n",
    "importlib.reload(data_loader.data_loader)\n",
    "from data_loader.data_loader import *\n",
    "\n",
    "importlib.reload(data_preprocessing.data_preprocessing)\n",
    "from data_preprocessing.data_preprocessing import *\n",
    "\n",
    "importlib.reload(models.standard_ml_models)\n",
    "from models.standard_ml_models import *\n",
    "\n",
    "importlib.reload(visualizations.visualizations)\n",
    "from visualizations.visualizations import *\n",
    "\n",
    "importlib.reload(utils.utils)\n",
    "from utils.utils import *\n",
    "\n",
    "# --- Notebook Configuration ---\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# --- Global Settings ---\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "id": "c4a4cc26a44cf154",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tnorlha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading data and splitting into train, validation, and test sets",
   "id": "e0f434313ee302bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:01.010348Z",
     "start_time": "2025-05-29T22:28:00.897898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, val_df, test_df = load_and_split_data()\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))"
   ],
   "id": "78615802f0f8833a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 81677\n",
      "Validation size: 10210\n",
      "Test size: 10210\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bag-of-words - Baseline models",
   "id": "e74138734bd8b710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:02.432516Z",
     "start_time": "2025-05-29T22:28:01.075540Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df, val_df, test_df)",
   "id": "1b9c1e0518dc588d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic Regression",
   "id": "9633d96f56167a22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:04.447599Z",
     "start_time": "2025-05-29T22:28:02.493575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "521daeba4efd9d08",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:04.584543Z",
     "start_time": "2025-05-29T22:28:04.571240Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "c896cbb2b2bf674e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:04.701135Z",
     "start_time": "2025-05-29T22:28:04.698635Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "d52c302fcb8c28ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "5d8537ad6f566830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:14.125842Z",
     "start_time": "2025-05-29T22:28:04.769974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Random Forest model\n",
    "y_train_pred_rf, y_val_pred_rf, y_test_pred_rf, model_rf = train_and_predict_random_forest(X_train, y_train, X_val, X_test)"
   ],
   "id": "ee3a437c28906137",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:14.210027Z",
     "start_time": "2025-05-29T22:28:14.199134Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_rf)",
   "id": "6a6927501a871514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.28      0.39      2191\n",
      "     neutral       0.63      0.89      0.73      4915\n",
      "    positive       0.68      0.49      0.57      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.64      0.55      0.57     10210\n",
      "weighted avg       0.64      0.64      0.61     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:14.282280Z",
     "start_time": "2025-05-29T22:28:14.279870Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_rf))",
   "id": "8bcc13b9ee2b6677",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923604309500489\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### XGBoost",
   "id": "31999ec6dc9eecd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:15.560424Z",
     "start_time": "2025-05-29T22:28:14.355513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a XGBoost model\n",
    "y_train_pred_xgb, y_val_pred_xgb, y_test_pred_xgb, model_xgb = train_and_predict_xgboost(X_train, y_train, X_val, X_test)"
   ],
   "id": "12e6f4dc316a9141",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:15.640399Z",
     "start_time": "2025-05-29T22:28:15.630098Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_xgb)",
   "id": "b0edd2f56abf5ea7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.41      2191\n",
      "     neutral       0.62      0.92      0.74      4915\n",
      "    positive       0.74      0.47      0.57      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.68      0.56      0.58     10210\n",
      "weighted avg       0.67      0.65      0.62     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:28:15.715885Z",
     "start_time": "2025-05-29T22:28:15.713743Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_xgb))",
   "id": "b0590323f529b80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8027913809990206\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### MLP",
   "id": "a30e1b9374828b8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:15.749574Z",
     "start_time": "2025-05-29T22:28:15.795930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a MLP model\n",
    "y_train_pred_mlp, y_val_pred_mlp, y_test_pred_mlp, model_mlp = train_and_predict_mlp(X_train, y_train, X_val, X_test)"
   ],
   "id": "485f30a1f3cd799b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:15.883606Z",
     "start_time": "2025-05-29T22:30:15.868979Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_mlp)",
   "id": "82f2cd1b220cb7ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.40      0.46      2191\n",
      "     neutral       0.69      0.77      0.73      4915\n",
      "    positive       0.61      0.60      0.60      3104\n",
      "\n",
      "    accuracy                           0.64     10210\n",
      "   macro avg       0.61      0.59      0.60     10210\n",
      "weighted avg       0.63      0.64      0.63     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:15.902294Z",
     "start_time": "2025-05-29T22:30:15.898054Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_mlp))",
   "id": "42f75bd83c0b82cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7782076395690499\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing\n",
    "\n",
    "### Lowercase"
   ],
   "id": "1ba3dfe49b9e5699"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:19.055050Z",
     "start_time": "2025-05-29T22:30:16.075566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lowercase = preprocess_ml_pipeline(train_df, [\"lowercase\"])\n",
    "val_df_lowercase = preprocess_ml_pipeline(val_df, [\"lowercase\"])\n",
    "test_df_lowercase = preprocess_ml_pipeline(test_df, [\"lowercase\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lowercase, val_df_lowercase, test_df_lowercase)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "bcc4355cd13abd41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "bag of words transforms to lowercase by default, so this step is redundant",
   "id": "c0ee0784ddfc9abf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Expand contractions",
   "id": "8cbf4ea059b428e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:23.752357Z",
     "start_time": "2025-05-29T22:30:19.148217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_expand_contractions = preprocess_ml_pipeline(train_df, [\"expand_contractions\"])\n",
    "val_df_expand_contractions = preprocess_ml_pipeline(val_df, [\"expand_contractions\"])\n",
    "test_df_expand_contractions = preprocess_ml_pipeline(test_df, [\"expand_contractions\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_expand_contractions, val_df_expand_contractions, test_df_expand_contractions)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "70097e3db0d62ebe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.40      0.49      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8057296767874633\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove emails",
   "id": "996630a7764abb28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:26.966318Z",
     "start_time": "2025-05-29T22:30:23.757359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_emails = preprocess_ml_pipeline(train_df, [\"remove_emails\"])\n",
    "val_df_remove_emails = preprocess_ml_pipeline(val_df, [\"remove_emails\"])\n",
    "test_df_remove_emails = preprocess_ml_pipeline(test_df, [\"remove_emails\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_emails, val_df_remove_emails, test_df_remove_emails)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "784a74f22652d890",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.804407443682664\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove urls",
   "id": "a8bed95d73570fad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:30.330336Z",
     "start_time": "2025-05-29T22:30:27.092801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_urls = preprocess_ml_pipeline(train_df, [\"remove_urls\"])\n",
    "val_df_remove_urls = preprocess_ml_pipeline(val_df, [\"remove_urls\"])\n",
    "test_df_remove_urls = preprocess_ml_pipeline(test_df, [\"remove_urls\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_urls, val_df_remove_urls, test_df_remove_urls)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "e7cb9028a5c22ecc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8041625857002939\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove digits",
   "id": "c94ea8da71923a54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:33.473847Z",
     "start_time": "2025-05-29T22:30:30.422783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_digits = preprocess_ml_pipeline(train_df, [\"remove_digits\"])\n",
    "val_df_remove_digits = preprocess_ml_pipeline(val_df, [\"remove_digits\"])\n",
    "test_df_remove_digits = preprocess_ml_pipeline(test_df, [\"remove_digits\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_digits, val_df_remove_digits, test_df_remove_digits)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "45bbe5c788e740d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.47      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.63      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8036728697355534\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove special characters",
   "id": "5df977e8ca2b3e81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:37.084268Z",
     "start_time": "2025-05-29T22:30:33.638122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_special_chars = preprocess_ml_pipeline(train_df, [\"remove_special_chars\"])\n",
    "val_df_remove_special_chars = preprocess_ml_pipeline(val_df, [\"remove_special_chars\"])\n",
    "test_df_remove_special_chars = preprocess_ml_pipeline(test_df, [\"remove_special_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_special_chars, val_df_remove_special_chars, test_df_remove_special_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "d2e564d8be3c634d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Collapse spaces",
   "id": "e25afaded505cd86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:41.465596Z",
     "start_time": "2025-05-29T22:30:38.108287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_collapse_spaces = preprocess_ml_pipeline(train_df, [\"collapse_spaces\"])\n",
    "val_df_collapse_spaces = preprocess_ml_pipeline(val_df, [\"collapse_spaces\"])\n",
    "test_df_collapse_spaces = preprocess_ml_pipeline(test_df, [\"collapse_spaces\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_collapse_spaces, val_df_collapse_spaces, test_df_collapse_spaces)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "dd34e3976a8cc92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8040646425073458\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This step is also redundant as it is already done.",
   "id": "399a0d6c7f7b450c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove accented characters",
   "id": "3451f786623274d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:45.618681Z",
     "start_time": "2025-05-29T22:30:41.473183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_accented_chars = preprocess_ml_pipeline(train_df, [\"remove_accented_chars\"])\n",
    "val_df_remove_accented_chars = preprocess_ml_pipeline(val_df, [\"remove_accented_chars\"])\n",
    "test_df_remove_accented_chars = preprocess_ml_pipeline(test_df, [\"remove_accented_chars\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_accented_chars, val_df_remove_accented_chars, test_df_remove_accented_chars)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "772008222d333f69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.69      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8037708129285015\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove stopwords",
   "id": "db41ddf1194c847c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:30:50.866386Z",
     "start_time": "2025-05-29T22:30:45.711713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_remove_stopwords = preprocess_ml_pipeline(train_df, [\"remove_stopwords\"])\n",
    "val_df_remove_stopwords = preprocess_ml_pipeline(val_df, [\"remove_stopwords\"])\n",
    "test_df_remove_stopwords = preprocess_ml_pipeline(test_df, [\"remove_stopwords\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_remove_stopwords, val_df_remove_stopwords, test_df_remove_stopwords)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "9739522499f070e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.34      0.43      2191\n",
      "     neutral       0.66      0.87      0.75      4915\n",
      "    positive       0.69      0.55      0.62      3104\n",
      "\n",
      "    accuracy                           0.66     10210\n",
      "   macro avg       0.65      0.59      0.60     10210\n",
      "weighted avg       0.66      0.66      0.64     10210\n",
      "\n",
      "0.800048971596474\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lemmatize",
   "id": "d8e0061f7338c8e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:31:03.512641Z",
     "start_time": "2025-05-29T22:30:52.330065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_lemmatize = preprocess_ml_pipeline(train_df, [\"lemmatize\"])\n",
    "val_df_lemmatize = preprocess_ml_pipeline(val_df, [\"lemmatize\"])\n",
    "test_df_lemmatize = preprocess_ml_pipeline(test_df, [\"lemmatize\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_lemmatize, val_df_lemmatize, test_df_lemmatize)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "60109b80b89118bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.39      0.47      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.70      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.60      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8032321253672869\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Filter valid words",
   "id": "16b443682df8f782"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:31:09.563271Z",
     "start_time": "2025-05-29T22:31:03.519497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_filter_valid_words = preprocess_ml_pipeline(train_df, [\"filter_valid_words\"])\n",
    "val_df_filter_valid_words = preprocess_ml_pipeline(val_df, [\"filter_valid_words\"])\n",
    "test_df_filter_valid_words = preprocess_ml_pipeline(test_df, [\"filter_valid_words\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_filter_valid_words, val_df_filter_valid_words, test_df_filter_valid_words)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "97368b7a4168dbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.59      0.36      0.45      2191\n",
      "     neutral       0.65      0.87      0.74      4915\n",
      "    positive       0.68      0.51      0.59      3104\n",
      "\n",
      "    accuracy                           0.65     10210\n",
      "   macro avg       0.64      0.58      0.59     10210\n",
      "weighted avg       0.65      0.65      0.63     10210\n",
      "\n",
      "0.794466209598433\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Removing non-English inputs in the training set",
   "id": "ec3c55565fbb0694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:54.559869Z",
     "start_time": "2025-05-29T22:33:54.366125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_df['language'] = train_df['text'].apply(safe_detect)\n",
    "train_df = pd.read_csv('../generated/language_detected/train_df_with_languages.csv')\n",
    "\n",
    "# Get indices of samples for each language as a dictionary\n",
    "language_indices = {lang: train_df.index[train_df['language'] == lang].tolist() for lang in train_df['language'].unique()}"
   ],
   "id": "d668820b8c947618",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:54.868164Z",
     "start_time": "2025-05-29T22:33:54.865693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_counts = {lang: len(indices) for lang, indices in language_indices.items()}\n",
    "print(language_counts)"
   ],
   "id": "276ede7845b501a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 77388, 'it': 223, 'fr': 533, 'so': 254, 'af': 504, 'unknown': 44, 'nl': 270, 'ca': 137, 'tl': 173, 'no': 279, 'sw': 62, 'et': 122, 'da': 304, 'sv': 78, 'id': 109, 'de': 293, 'sq': 46, 'fi': 38, 'pl': 64, 'pt': 82, 'vi': 69, 'zh-cn': 4, 'cy': 192, 'ro': 112, 'es': 124, 'hu': 33, 'sl': 22, 'tr': 34, 'lt': 13, 'hr': 15, 'cs': 24, 'lv': 10, 'sk': 17, 'ja': 3, 'uk': 2}\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:54.986487Z",
     "start_time": "2025-05-29T22:33:54.981708Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.loc[language_indices['it'][:5]].copy()",
   "id": "4794689d1512fa95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          text  labels language  \\\n",
       "15                     I give a 5 on ambiance.       2       it   \n",
       "76                                      Hello!       1       it   \n",
       "514  Second: I've never had tomatoes ll pizza.       1       it   \n",
       "549                           I'm a carnivore.       1       it   \n",
       "563                          I prefer Spinatos       1       it   \n",
       "\n",
       "    transformer_language  \n",
       "15                 en-US  \n",
       "76                 en-US  \n",
       "514                en-US  \n",
       "549                en-US  \n",
       "563                ro-RO  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>language</th>\n",
       "      <th>transformer_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I give a 5 on ambiance.</td>\n",
       "      <td>2</td>\n",
       "      <td>it</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Second: I've never had tomatoes ll pizza.</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>I'm a carnivore.</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>en-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>I prefer Spinatos</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>ro-RO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Using this library leads to many classification error.\n",
    "\n",
    "\n",
    "However, let's just keep the english samples and remove the rest for training, just to have an idea of if we are going into the right direction."
   ],
   "id": "5da9e4a4de8af0bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:55.207803Z",
     "start_time": "2025-05-29T22:33:55.200118Z"
    }
   },
   "cell_type": "code",
   "source": "english_train_df = train_df.loc[language_indices['en']].copy()",
   "id": "bd12a2e8c4377156",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:56.728033Z",
     "start_time": "2025-05-29T22:33:55.304668Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(english_train_df, val_df, test_df)",
   "id": "f1429ad8ea365418",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.128013Z",
     "start_time": "2025-05-29T22:33:56.801518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "38af95a1a897ea94",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.317552Z",
     "start_time": "2025-05-29T22:33:59.297792Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "da82aae23a2e1ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.39      0.48      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.69      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.422063Z",
     "start_time": "2025-05-29T22:33:59.419938Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "8320ac1c5cdaae44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8034280117531831\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Trying a different language detection method: using a fine-tuned classification model, which is more robust and has better performance.",
   "id": "46ea64274d4d4ece"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.512200Z",
     "start_time": "2025-05-29T22:33:59.510659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_df_with_languages = add_detected_language_column(train_df)\n",
    "train_df_with_languages = train_df"
   ],
   "id": "44c03e002065cde2",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.746850Z",
     "start_time": "2025-05-29T22:33:59.590345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get indices of samples for each language as a dictionary\n",
    "language_indices = {lang: train_df_with_languages.index[train_df_with_languages['transformer_language'] == lang].tolist() for lang in train_df_with_languages['transformer_language'].unique()}"
   ],
   "id": "db9fe8a36064800c",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.825754Z",
     "start_time": "2025-05-29T22:33:59.823879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "language_counts = {lang: len(indices) for lang, indices in language_indices.items()}\n",
    "print(language_counts)"
   ],
   "id": "f3a6b7878955e30c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en-US': 79095, 'fr-FR': 373, 'ar-SA': 815, 'nl-NL': 166, 'km-KH': 106, 'es-ES': 69, 'jv-ID': 45, 'ro-RO': 67, 'de-DE': 146, 'sv-SE': 36, 'tl-PH': 72, 'ms-MY': 18, 'pt-PT': 38, 'cy-GB': 51, 'lv-LV': 36, 'zh-CN': 5, 'fi-FI': 46, 'id-ID': 12, 'pl-PL': 38, 'sw-KE': 40, 'tr-TR': 10, 'hu-HU': 6, 'nb-NO': 18, 'zh-TW': 21, 'it-IT': 39, 'af-ZA': 124, 'te-IN': 3, 'mn-MN': 12, 'th-TH': 11, 'az-AZ': 22, 'kn-IN': 26, 'hi-IN': 9, 'bn-BD': 7, 'ur-PK': 3, 'ja-JP': 27, 'is-IS': 2, 'vi-VN': 9, 'sl-SL': 9, 'ka-GE': 11, 'da-DK': 8, 'ml-IN': 2, 'he-IL': 7, 'sq-AL': 6, 'hy-AM': 3, 'ru-RU': 2, 'ta-IN': 5, 'am-ET': 1}\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:33:59.915853Z",
     "start_time": "2025-05-29T22:33:59.912247Z"
    }
   },
   "cell_type": "code",
   "source": "train_df_with_languages.loc[language_indices['fr-FR'][:5]].copy()",
   "id": "2b863c9390ea31f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  labels language  \\\n",
       "20   Une chance que les portions étaient aussi géné...       1       fr   \n",
       "271                                      Bon appétit !       2       fr   \n",
       "301      One ca n't deny its seriousness and quality .       2       en   \n",
       "354                                  2 for 1 coup-ons.       1       en   \n",
       "765  They got your head, ear, neck, hands and your ...       1       en   \n",
       "\n",
       "    transformer_language  \n",
       "20                 fr-FR  \n",
       "271                fr-FR  \n",
       "301                fr-FR  \n",
       "354                fr-FR  \n",
       "765                fr-FR  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>language</th>\n",
       "      <th>transformer_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Une chance que les portions étaient aussi géné...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Bon appétit !</td>\n",
       "      <td>2</td>\n",
       "      <td>fr</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>One ca n't deny its seriousness and quality .</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2 for 1 coup-ons.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>They got your head, ear, neck, hands and your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>fr-FR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:00.031270Z",
     "start_time": "2025-05-29T22:34:00.023316Z"
    }
   },
   "cell_type": "code",
   "source": "english_train_df = train_df_with_languages.loc[language_indices['en-US']].copy()",
   "id": "f9e7a26f0c266cfa",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:01.414585Z",
     "start_time": "2025-05-29T22:34:00.116474Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(english_train_df, val_df, test_df)",
   "id": "cf392f6560320b36",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:03.267786Z",
     "start_time": "2025-05-29T22:34:01.563656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)"
   ],
   "id": "84e49bba2319bc3b",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:03.429574Z",
     "start_time": "2025-05-29T22:34:03.410421Z"
    }
   },
   "cell_type": "code",
   "source": "print_evaluation(y_test, y_test_pred_lr)",
   "id": "401e53d5ff7c4b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.39      0.47      2191\n",
      "     neutral       0.67      0.86      0.76      4915\n",
      "    positive       0.69      0.56      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.66      0.60      0.62     10210\n",
      "weighted avg       0.66      0.67      0.65     10210\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:03.535605Z",
     "start_time": "2025-05-29T22:34:03.533388Z"
    }
   },
   "cell_type": "code",
   "source": "print(L_score(y_test, y_test_pred_lr))",
   "id": "cb3be5d43f9e9e0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024485798237022\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove emails + urls and expand contractions",
   "id": "2a664851eb6d50b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T22:34:08.665889Z",
     "start_time": "2025-05-29T22:34:03.615445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_final = preprocess_ml_pipeline(train_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "val_df_final = preprocess_ml_pipeline(val_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "test_df_final = preprocess_ml_pipeline(test_df, [\"remove_emails\", \"remove_urls\", \"expand_contractions\"])\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, vectorizer = preprocess_text_with_count_vectorizer(train_df_final, val_df_final, test_df_final)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "y_train_pred_lr, y_val_pred_lr, y_test_pred_lr, model_lr = train_and_predict_logistic_regression(X_train, y_train, X_val, X_test)\n",
    "\n",
    "print_evaluation(y_test, y_test_pred_lr)\n",
    "print(L_score(y_test, y_test_pred_lr))"
   ],
   "id": "7b6a527c4f07d5ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.40      0.49      2191\n",
      "     neutral       0.68      0.86      0.76      4915\n",
      "    positive       0.70      0.57      0.62      3104\n",
      "\n",
      "    accuracy                           0.67     10210\n",
      "   macro avg       0.67      0.61      0.62     10210\n",
      "weighted avg       0.67      0.67      0.66     10210\n",
      "\n",
      "0.8062683643486778\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "\n",
    "| Model                                      | L_score | Accuracy | Precision (N/Ne/P)   | Recall (N/Ne/P)       | F1-score (N/Ne/P)     | Weighted F1 |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| LogReg                                     | 0.8041  | 0.67     | 0.61 / 0.68 / 0.69  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| LogReg + expand contractions                | 0.8057  | 0.67     | 0.62 / 0.68 / 0.70  | 0.40 / 0.86 / 0.56    | 0.49 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg + remove emails                       | 0.8044  | 0.67     | 0.61 / 0.68 / 0.70  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg + remove urls                         | 0.8042  | 0.67     | 0.61 / 0.68 / 0.69  | 0.39 / 0.86 / 0.57    | 0.48 / 0.76 / 0.62    | 0.66        |\n",
    "| LogReg combined (expand contractions, remove urls + emails) | 0.8063  | 0.67     | 0.62 / 0.68 / 0.70  | 0.40 / 0.86 / 0.57    | 0.49 / 0.76 / 0.62    | 0.66        |\n",
    "|--------------------------------------------|---------|----------|---------------------|-----------------------|-----------------------|-------------|\n",
    "| RF                                         | 0.7924  | 0.64     | 0.61 / 0.63 / 0.68  | 0.28 / 0.89 / 0.49    | 0.39 / 0.73 / 0.57    | 0.61        |\n",
    "| XGBoost                                    | 0.8028  | 0.65     | 0.67 / 0.62 / 0.74  | 0.29 / 0.92 / 0.47    | 0.41 / 0.74 / 0.57    | 0.62        |\n",
    "| MLP                                        | 0.7782  | 0.64     | 0.53 / 0.69 / 0.61  | 0.40 / 0.77 / 0.60    | 0.46 / 0.73 / 0.60    | 0.63        |\n",
    "\n",
    "\n",
    "We can see that the preprocessing steps have a small impact on the model performance. The best performing model is the one with the \"expand_contractions\" step, which has a slight improvement over the baseline. The other steps have negligible effects on the performance.\n",
    "\n",
    "To attain better results, we will explore with fine-tuning Roberta in the next notebook. We will explore ways to sanitize and augment the dataset using LLMs and various other techniques."
   ],
   "id": "fb3da437b2280536"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2231cf3e6fc07b3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
